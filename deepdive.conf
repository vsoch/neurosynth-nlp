deepdive {

  # Variables
  schema.variables {
      has_cognitive_concept.is_true: Boolean  
  }

  # Extractors
  extraction.extractors {

    # Extractor #0: NeuroSynth Articles to Sentences
    ext_sentences {
      input: """
        SELECT  article_id, text
        FROM    articles
        ORDER BY article_id ASC
        """
      output_relation : "sentences"
      udf             : "examples/nlp_extractor/run.sh -k article_id -v text -l 100 -t 4"
    }

    # Extractor 1: Clean output tables of all extractors
    ext_clear_table {
      style: "sql_extractor"
      sql: """
        DELETE FROM region_mentions;
        DELETE FROM concept_mentions;
        """
    }

    # Extractor 2: Extract mentions of brain regions
    ext_regions {

      # The style of the extractor
      style: "tsv_extractor"

      # An input to the extractor is a row (tuple) of the following query:
      input: """
          SELECT  sentence_id,
                  array_to_string(words, '~^~'),
                  array_to_string(ner_tags, '~^~')
          FROM    sentences
          """

      # output of extractor will be written to this table:
      output_relation: "region_mentions"

      # This user-defined function will be performed on each row (tuple) of input query:
      udf: ${APP_HOME}"/slurm/3.ext_regions.py "${APP_HOME}"/udf/NER/brain_regions.json"

      dependencies: ["ext_clear_table"]

    }

    # Extractor 3: Extract mentions of cognitive concepts
    ext_concepts {

      # The style of the extractor
      style: "tsv_extractor"

      # An input to the extractor is a row (tuple) of the following query:
      input: """
          SELECT  sentence_id,
                  array_to_string(words, '~^~'),
                  array_to_string(ner_tags, '~^~')
          FROM    sentences
          """

      # output of extractor will be written to this table:
      output_relation: "concept_mentions"

      # This user-defined function will be performed on each row (tuple) of input query:
      udf: ${APP_HOME}"/slurm/3.ext_concepts.py"

      dependencies: ["ext_clear_table"]

    }

    # Extractor 4: Extract mention relation candidates
    ext_has_cognitive_concept_candidates {

      # The style of the extractor
      style: "tsv_extractor"

      input: """
       SELECT r1.sentence_id,
              r1.mention_id, r1.text,
              c1.mention_id, c1.text
        FROM  region_mentions r1,
              concept_mentions c1
        WHERE r1.sentence_id = c2.sentence_id;
        """

      output_relation: "has_cognitive_concept"
      udf: ${APP_HOME}"/udf/ext_has_cognitive_concept.py"

      # Run this extractor after "ext_concepts"
      #dependencies: ["ext_concepts"]

    }


    # Extractor 4: Extract mention relation candidates
    ext_has_related_concept_candidates {

      # The style of the extractor
      style: tsv_extractor

      # Each input (c1, c2) is a pair of concept mentions
      input: """
       SELECT c1.sentence_id,
              c1.mention_id, c1.text,
              c2.mention_id, c2.text
        FROM  concept_mentions c1,
              concept_mentions c2
        WHERE c1.sentence_id = c2.sentence_id
          AND c1.mention_id != c2.mention_id;
          """

      output_relation: "has_related_concept"
      udf: ${APP_HOME}"/udf/ext_has_related_concept.py"

      dependencies: ["ext_concepts"]

    }

    # Extractor 5: Extract features for relation candidates
    ext_has_related_concept_features {
      style: "tsv_extractor"
      input: """
        SELECT  array_to_string(words, '~^~'),
                has_related_concept.relation_id,
                c1.start_position,
                c1.length,
                c2.start_position,
                c2.length
        FROM    has_related_concept,
                concept_mentions c1,
                concept_mentions c2,
                sentences
        WHERE   has_related_concept.concept1_id = c1.mention_id
          AND   has_related_concept.concept2_id = c2.mention_id
          AND   has_related_concept.sentence_id = sentences.sentence_id;
        """

      output_relation : "has_related_concept_features"
      udf             : ${APP_HOME}"/udf/ext_has_related_concept_features.py"

      dependencies    : ["ext_has_related_concept_candidates"]
    }


    # Extractor 6: Extract features for relation candidates
    ext_has_cognitive_concept_features {
      style: "tsv_extractor"
      input: """
        SELECT  array_to_string(words, '~^~'),
                has_cognitive_concept.relation_id,
                r1.start_position,
                r1.length,
                c1.start_position,
                c1.length
        FROM    has_cognitive_concept,
                region_mentions r1,
                concept_mentions c1,
                sentences
        WHERE   has_cognitive_concept.region_id = r1.mention_id
          AND   has_cognitive_concept.concept_id = c1.mention_id
          AND   has_cognitive_concept.sentence_id = sentences.sentence_id;
        """

      output_relation : "has_cognitive_concept_features"
      udf             : ${APP_HOME}"/udf/ext_has_cognitive_concept_features.py"

      dependencies    : ["ext_has_cognitive_concept_candidates"]
    }


    # TEST DUMMY
    dummy_extractor {

	style: tsv_extractor
	input: """ SELECT 1 """
	output_relation: dummy
	udf: "cat"

    }

  }

  # Inference rules
  inference.factors: {

    # A simple logistic regression rule
    # We require developers to select:
    #   - reserved "id" column,
    #   - variable column,
    #   - weight dependencies,
    # for variable tables.
    f_has_related_concept_features {

      # input to the inference rule is all the has_related_concept candidate relations,
      #   as well as the features connected to them:
      input_query: """
        SELECT  has_related_concept.id AS "has_related_concept.id",
                has_related_concept.is_true AS "has_related_concept.is_true",
                feature
        FROM    has_related_concept,
                has_related_concept_features
        WHERE   has_related_concept_features.relation_id = has_related_concept.relation_id
        """

      # Factor function:
      function: "IsTrue(has_related_concept.is_true)"

      # Weight of the factor is decided by the value of "feature" column in input query
      weight: "?(feature)"

    }

  }


  # # An example of how to use the last factor graph:
  # pipeline.relearn_from: ${DEEPDIVE_HOME}"/out/2014-12-22T153233/"

  # Default is to use the full pipeline, equivalent to:
  # pipeline.run: "all"
  # pipeline.pipelines.all: [
  #   "ext_people",
  #   "ext_has_spouse_candidates",
  #   "ext_has_spouse_features",
  #   "f_has_spouse_features"
  #   ]

  # Specify a holdout fraction to hold out randomly
  calibration.holdout_fraction: 0.25

  # A more scientific way is to hold out by sentence:
  calibration.holdout_query:"""
    DROP TABLE IF EXISTS holdout_sentence_ids CASCADE;

    CREATE TABLE holdout_sentence_ids AS
    SELECT sentence_id FROM sentences WHERE RANDOM() < 0.25;

    INSERT INTO dd_graph_variables_holdout(variable_id)
    SELECT id FROM has_related_concept WHERE sentence_id IN
    (SELECT * FROM holdout_sentence_ids);
  """

  # You may also try tuning sampler arguments:
  # sampler.sampler_args: "-l 1000 -s 1 -i 1000 --alpha 0.1 --diminish 0.99"


  # PIPELINES
  pipeline.pipelines.nlp_extract: [
    "ext_sentences"    # NLP extractor, takes very long
  ]

  pipeline.pipelines.mentions_extract: [
    "ext_clear_table", "ext_regions","ext_concepts"
  ]

  pipeline.pipelines.has_related_concept: [
    "ext_has_related_concept_candidates",  "ext_has_related_concept_features"
  ]

  pipeline.pipelines.has_cognitive_concept: [
    "ext_has_cognitive_concept_candidates"
  ]

  pipeline.pipelines.dummy_extractor: [
    "dummy_extractor"    # NLP extractor, takes very long
  ]


}
