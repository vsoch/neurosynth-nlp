deepdive {

  # Variables
  schema.variables {
      has_cognitive_concept.is_true: Boolean,
      has_related_concept.is_true: Boolean,  
  }

  # Extractors
  extraction.extractors {

    # Extractor 4: Extract mention relation candidates
    ext_has_cognitive_concept_candidates {

      # The style of the extractor
      style: "tsv_extractor"

      input: """
       SELECT r1.sentence_id,
              r1.mention_id, r1.text,
              c1.mention_id, c1.text
        FROM  region_mentions r1,
              concept_mentions c1
        WHERE r1.sentence_id = c2.sentence_id;
        """

      output_relation: "has_cognitive_concept"
      udf: ${APP_HOME}"/udf/ext_has_cognitive_concept.py"

    }


    # Extractor 4: Extract mention relation candidates
    ext_has_related_concept_candidates {

      # The style of the extractor
      style: tsv_extractor

      # Each input (c1, c2) is a pair of concept mentions
      input: """
       SELECT c1.sentence_id,
              c1.mention_id, c1.text,
              c2.mention_id, c2.text
        FROM  concept_mentions c1,
              concept_mentions c2
        WHERE c1.sentence_id = c2.sentence_id
          AND c1.mention_id != c2.mention_id;
          """

      output_relation: "has_related_concept"
      udf: ${APP_HOME}"/udf/ext_has_related_concept.py"

    }

    # Extractor 5: Extract features for relation candidates
    ext_has_related_concept_features {
      style: "tsv_extractor"
      input: """
        SELECT  array_to_string(words, '~^~'),
                has_related_concept.relation_id,
                c1.start_position,
                c1.length,
                c2.start_position,
                c2.length
        FROM    has_related_concept,
                concept_mentions c1,
                concept_mentions c2,
                sentences
        WHERE   has_related_concept.concept1_id = c1.mention_id
          AND   has_related_concept.concept2_id = c2.mention_id
          AND   has_related_concept.sentence_id = sentences.sentence_id;
        """

      output_relation : "has_related_concept_features"
      udf             : ${APP_HOME}"/udf/ext_has_related_concept_features.py"

      dependencies    : ["ext_has_related_concept_candidates"]
    }


    # Extractor 6: Extract features for relation candidates
    ext_has_cognitive_concept_features {
      style: "tsv_extractor"
      input: """
        SELECT  array_to_string(words, '~^~'),
                has_cognitive_concept.relation_id,
                r1.start_position,
                r1.length,
                c1.start_position,
                c1.length
        FROM    has_cognitive_concept,
                region_mentions r1,
                concept_mentions c1,
                sentences
        WHERE   has_cognitive_concept.region_id = r1.mention_id
          AND   has_cognitive_concept.concept_id = c1.mention_id
          AND   has_cognitive_concept.sentence_id = sentences.sentence_id;
        """

      output_relation : "has_cognitive_concept_features"
      udf             : ${APP_HOME}"/udf/ext_has_cognitive_concept_features.py"

      dependencies    : ["ext_has_cognitive_concept_candidates"]
    }

  }

  # Inference rules
  inference.factors: {

    # A simple logistic regression rule
    # We require developers to select:
    #   - reserved "id" column,
    #   - variable column,
    #   - weight dependencies,
    # for variable tables.
    f_has_related_concept_features {

      # input to the inference rule is all the has_related_concept candidate relations,
      #   as well as the features connected to them:
      input_query: """
        SELECT  has_related_concept.id AS "has_related_concept.id",
                has_related_concept.is_true AS "has_related_concept.is_true",
                feature
        FROM    has_related_concept,
                has_related_concept_features
        WHERE   has_related_concept_features.relation_id = has_related_concept.relation_id
        """

      # Factor function:
      function: "IsTrue(has_related_concept.is_true)"

      # Weight of the factor is decided by the value of "feature" column in input query
      weight: "?(feature)"

    }

  }


  # # An example of how to use the last factor graph:
  # pipeline.relearn_from: ${DEEPDIVE_HOME}"/out/2014-12-22T153233/"

  # Default is to use the full pipeline, equivalent to:
  pipeline.run: "has_related_concept_inference"
  # pipeline.pipelines.all: [
  #   "ext_people",
  #   "ext_has_spouse_candidates",
  #   "ext_has_spouse_features",
  #   "f_has_spouse_features"
  #   ]

  # Specify a holdout fraction to hold out randomly
  calibration.holdout_fraction: 0.25

  # A more scientific way is to hold out by sentence:
  calibration.holdout_query:"""
    DROP TABLE IF EXISTS holdout_sentence_ids CASCADE;

    CREATE TABLE holdout_sentence_ids AS
    SELECT sentence_id FROM sentences WHERE RANDOM() < 0.25;

    INSERT INTO dd_graph_variables_holdout(variable_id)
    SELECT id FROM has_related_concept WHERE sentence_id IN
    (SELECT * FROM holdout_sentence_ids);
  """

  # You may also try tuning sampler arguments:
  # sampler.sampler_args: "-l 1000 -s 1 -i 1000 --alpha 0.1 --diminish 0.99"


  # PIPELINES

  pipeline.pipelines.has_related_concept: [
    "ext_has_related_concept_candidates",  "ext_has_related_concept_features"
  ]

  pipeline.pipelines.has_cognitive_concept: [
    "ext_has_cognitive_concept_candidates"
  ]

  pipeline.pipelines.has_related_concept_inference: [
    "f_has_related_concept_features"
  ]


}
